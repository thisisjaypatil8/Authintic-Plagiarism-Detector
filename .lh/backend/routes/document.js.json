{
    "sourceFile": "backend/routes/document.js",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 8,
            "patches": [
                {
                    "date": 1762431758746,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1762434279195,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,61 +1,52 @@\n+// backend/routes/document.js\r\n+\r\n const express = require('express');\r\n const multer = require('multer');\r\n const fs = require('fs');\r\n const axios = require('axios');\r\n-const auth = require('../middleware/authMiddleware'); // âœ… Secure routes\r\n+const router = express.Router();\r\n \r\n-const router = express.Router();\r\n const upload = multer({ dest: 'uploads/' });\r\n \r\n-// -----------------------------------------\r\n // @route   POST /api/documents/upload\r\n-// @desc    Uploads a document and analyzes via NLP microservice\r\n-// @access  Private\r\n-// -----------------------------------------\r\n-router.post('/upload', auth, upload.single('document'), async (req, res) => {\r\n+router.post('/upload', upload.single('document'), async (req, res) => {\r\n     if (!req.file) {\r\n         return res.status(400).send('No file uploaded.');\r\n     }\r\n \r\n-    const filePath = req.file.path;\r\n-\r\n     try {\r\n-        const fileContent = fs.readFileSync(filePath, 'utf8');\r\n+        const fileContent = fs.readFileSync(req.file.path, 'utf8');\r\n \r\n-        // âœ… Updated endpoint to match new Python service route\r\n-        const nlpResponse = await axios.post('http://localhost:5001/analyze', {\r\n+        // âœ… Correct route on NLP service\r\n+        const nlpResponse = await axios.post('http://localhost:5001/api/check', {\r\n             text: fileContent\r\n         });\r\n \r\n+        fs.unlinkSync(req.file.path); // delete temp file\r\n         res.status(200).json(nlpResponse.data);\r\n+\r\n     } catch (error) {\r\n         console.error('Error calling NLP service:', error.message);\r\n         res.status(500).send('Error analyzing the document.');\r\n-    } finally {\r\n-        // âœ… Always delete uploaded temp file safely\r\n-        if (fs.existsSync(filePath)) fs.unlinkSync(filePath);\r\n     }\r\n });\r\n \r\n-// -----------------------------------------\r\n-// @route   POST /api/documents/rewrite\r\n-// @desc    Proxies rewrite requests securely to the Python microservice\r\n-// @access  Private\r\n-// -----------------------------------------\r\n-router.post('/rewrite', auth, async (req, res) => {\r\n+// --- NEW REWRITE ROUTE ---\r\n+router.post('/rewrite', async (req, res) => {\r\n     const { sentence } = req.body;\r\n     if (!sentence) {\r\n         return res.status(400).json({ msg: 'Sentence is required' });\r\n     }\r\n \r\n     try {\r\n-        // âœ… Matches new /rewrite route in app.py\r\n-        const nlpResponse = await axios.post('http://localhost:5001/rewrite', {\r\n-            sentence,\r\n-            api_key: process.env.GEMINI_API_KEY\r\n-        });\r\n-\r\n+        const nlpResponse = await axios.post(\r\n+            'http://localhost:5001/api/rewrite',\r\n+            {\r\n+                sentence,\r\n+                api_key: process.env.GEMINI_API_KEY\r\n+            }\r\n+        );\r\n         res.json(nlpResponse.data);\r\n     } catch (error) {\r\n         console.error('Error proxying rewrite request:', error.message);\r\n         res.status(500).send('Error rewriting the sentence.');\r\n"
                },
                {
                    "date": 1762436810961,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,14 +1,4 @@\n-// backend/routes/document.js\r\n-\r\n-const express = require('express');\r\n-const multer = require('multer');\r\n-const fs = require('fs');\r\n-const axios = require('axios');\r\n-const router = express.Router();\r\n-\r\n-const upload = multer({ dest: 'uploads/' });\r\n-\r\n // @route   POST /api/documents/upload\r\n router.post('/upload', upload.single('document'), async (req, res) => {\r\n     if (!req.file) {\r\n         return res.status(400).send('No file uploaded.');\r\n@@ -16,41 +6,52 @@\n \r\n     try {\r\n         const fileContent = fs.readFileSync(req.file.path, 'utf8');\r\n \r\n-        // âœ… Correct route on NLP service\r\n-        const nlpResponse = await axios.post('http://localhost:5001/api/check', {\r\n+        // Send to NLP service\r\n+        const nlpResponse = await axios.post('http://localhost:5001/analyze', {\r\n             text: fileContent\r\n         });\r\n \r\n-        fs.unlinkSync(req.file.path); // delete temp file\r\n-        res.status(200).json(nlpResponse.data);\r\n+        // Cleanup\r\n+        fs.unlinkSync(req.file.path);\r\n \r\n-    } catch (error) {\r\n-        console.error('Error calling NLP service:', error.message);\r\n-        res.status(500).send('Error analyzing the document.');\r\n-    }\r\n-});\r\n+        const analysis = nlpResponse.data;\r\n \r\n-// --- NEW REWRITE ROUTE ---\r\n-router.post('/rewrite', async (req, res) => {\r\n-    const { sentence } = req.body;\r\n-    if (!sentence) {\r\n-        return res.status(400).json({ msg: 'Sentence is required' });\r\n-    }\r\n+        // Build document visualizer array\r\n+        const flaggedSections = analysis.flagged_sections || [];\r\n+        let visualizer = [];\r\n \r\n-    try {\r\n-        const nlpResponse = await axios.post(\r\n-            'http://localhost:5001/api/rewrite',\r\n-            {\r\n-                sentence,\r\n-                api_key: process.env.GEMINI_API_KEY\r\n+        // Split text by sentence (basic, you can improve later)\r\n+        const sentences = fileContent.match(/[^.!?]+[.!?]/g) || [fileContent];\r\n+\r\n+        sentences.forEach(sentence => {\r\n+            const matched = flaggedSections.find(f => sentence.includes(f.text));\r\n+            if (matched) {\r\n+                visualizer.push({\r\n+                    text: sentence.trim(),\r\n+                    type: matched.type,\r\n+                    match: {\r\n+                        source: matched.source,\r\n+                        similarity: matched.similarity\r\n+                    }\r\n+                });\r\n+            } else {\r\n+                visualizer.push({\r\n+                    text: sentence.trim(),\r\n+                    type: null\r\n+                });\r\n             }\r\n-        );\r\n-        res.json(nlpResponse.data);\r\n+        });\r\n+\r\n+        // Send combined result\r\n+        res.status(200).json({\r\n+            overall_score: analysis.overall_score || 0,\r\n+            flagged_sections: flaggedSections,\r\n+            document_visualizer: visualizer\r\n+        });\r\n+\r\n     } catch (error) {\r\n-        console.error('Error proxying rewrite request:', error.message);\r\n-        res.status(500).send('Error rewriting the sentence.');\r\n+        console.error('Error calling NLP service:', error.message);\r\n+        res.status(500).send('Error analyzing the document.');\r\n     }\r\n });\r\n-\r\n-module.exports = router;\r\n"
                },
                {
                    "date": 1762436962776,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,39 +1,49 @@\n-// @route   POST /api/documents/upload\r\n+// backend/routes/document.js\r\n+\r\n+const express = require('express');\r\n+const multer = require('multer');\r\n+const fs = require('fs');\r\n+const axios = require('axios');\r\n+const router = express.Router();\r\n+\r\n+const upload = multer({ dest: 'uploads/' });\r\n+\r\n+// --------------------------------------\r\n+// ðŸ“„ ROUTE: Upload and Analyze Document\r\n+// --------------------------------------\r\n router.post('/upload', upload.single('document'), async (req, res) => {\r\n     if (!req.file) {\r\n         return res.status(400).send('No file uploaded.');\r\n     }\r\n \r\n     try {\r\n         const fileContent = fs.readFileSync(req.file.path, 'utf8');\r\n \r\n-        // Send to NLP service\r\n+        // Call the NLP microservice for analysis\r\n         const nlpResponse = await axios.post('http://localhost:5001/analyze', {\r\n             text: fileContent\r\n         });\r\n \r\n-        // Cleanup\r\n+        // Delete temporary uploaded file\r\n         fs.unlinkSync(req.file.path);\r\n \r\n         const analysis = nlpResponse.data;\r\n-\r\n-        // Build document visualizer array\r\n         const flaggedSections = analysis.flagged_sections || [];\r\n-        let visualizer = [];\r\n \r\n-        // Split text by sentence (basic, you can improve later)\r\n+        // --- ðŸ” Build document visualizer data ---\r\n+        const visualizer = [];\r\n         const sentences = fileContent.match(/[^.!?]+[.!?]/g) || [fileContent];\r\n \r\n         sentences.forEach(sentence => {\r\n-            const matched = flaggedSections.find(f => sentence.includes(f.text));\r\n-            if (matched) {\r\n+            const match = flaggedSections.find(f => sentence.includes(f.text));\r\n+            if (match) {\r\n                 visualizer.push({\r\n                     text: sentence.trim(),\r\n-                    type: matched.type,\r\n+                    type: match.type,\r\n                     match: {\r\n-                        source: matched.source,\r\n-                        similarity: matched.similarity\r\n+                        source: match.source,\r\n+                        similarity: match.similarity\r\n                     }\r\n                 });\r\n             } else {\r\n                 visualizer.push({\r\n@@ -42,9 +52,9 @@\n                 });\r\n             }\r\n         });\r\n \r\n-        // Send combined result\r\n+        // --- âœ… Send combined analysis + visualization ---\r\n         res.status(200).json({\r\n             overall_score: analysis.overall_score || 0,\r\n             flagged_sections: flaggedSections,\r\n             document_visualizer: visualizer\r\n@@ -54,4 +64,30 @@\n         console.error('Error calling NLP service:', error.message);\r\n         res.status(500).send('Error analyzing the document.');\r\n     }\r\n });\r\n+\r\n+// --------------------------------------\r\n+// âœï¸ ROUTE: Rewrite Sentence\r\n+// --------------------------------------\r\n+router.post('/rewrite', async (req, res) => {\r\n+    const { sentence } = req.body;\r\n+    if (!sentence) {\r\n+        return res.status(400).json({ msg: 'Sentence is required' });\r\n+    }\r\n+\r\n+    try {\r\n+        const nlpResponse = await axios.post(\r\n+            'http://localhost:5001/api/rewrite',\r\n+            {\r\n+                sentence,\r\n+                api_key: process.env.GEMINI_API_KEY\r\n+            }\r\n+        );\r\n+        res.json(nlpResponse.data);\r\n+    } catch (error) {\r\n+        console.error('Error proxying rewrite request:', error.message);\r\n+        res.status(500).send('Error rewriting the sentence.');\r\n+    }\r\n+});\r\n+\r\n+module.exports = router;\r\n"
                },
                {
                    "date": 1762439576506,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -18,18 +18,21 @@\n \r\n     try {\r\n         const fileContent = fs.readFileSync(req.file.path, 'utf8');\r\n \r\n-        // Call the NLP microservice for analysis\r\n+        // ðŸ”¹ Call NLP microservice\r\n         const nlpResponse = await axios.post('http://localhost:5001/analyze', {\r\n             text: fileContent\r\n         });\r\n \r\n-        // Delete temporary uploaded file\r\n+        // Delete temp uploaded file\r\n         fs.unlinkSync(req.file.path);\r\n \r\n         const analysis = nlpResponse.data;\r\n-        const flaggedSections = analysis.flagged_sections || [];\r\n+        const flaggedSections = (analysis.flagged_sections || []).map(f => ({\r\n+            ...f,\r\n+            type: f.type || (f.similarity > 85 ? 'direct' : 'paraphrased')\r\n+        }));\r\n \r\n         // --- ðŸ” Build document visualizer data ---\r\n         const visualizer = [];\r\n         const sentences = fileContent.match(/[^.!?]+[.!?]/g) || [fileContent];\r\n@@ -40,25 +43,26 @@\n                 visualizer.push({\r\n                     text: sentence.trim(),\r\n                     type: match.type,\r\n                     match: {\r\n-                        source: match.source,\r\n-                        similarity: match.similarity\r\n+                        source: match.source || 'Unknown',\r\n+                        similarity: match.similarity || 0\r\n                     }\r\n                 });\r\n             } else {\r\n                 visualizer.push({\r\n                     text: sentence.trim(),\r\n-                    type: null\r\n+                    type: 'unique'\r\n                 });\r\n             }\r\n         });\r\n \r\n-        // --- âœ… Send combined analysis + visualization ---\r\n+        // âœ… Send combined data\r\n         res.status(200).json({\r\n             overall_score: analysis.overall_score || 0,\r\n             flagged_sections: flaggedSections,\r\n-            document_visualizer: visualizer\r\n+            document_visualizer: visualizer,\r\n+            full_text: fileContent\r\n         });\r\n \r\n     } catch (error) {\r\n         console.error('Error calling NLP service:', error.message);\r\n@@ -76,15 +80,15 @@\n     }\r\n \r\n     try {\r\n         const nlpResponse = await axios.post(\r\n-            'http://localhost:5001/api/rewrite',\r\n-            {\r\n-                sentence,\r\n-                api_key: process.env.GEMINI_API_KEY\r\n-            }\r\n+            'http://localhost:5001/rewrite',\r\n+            { sentence }\r\n         );\r\n-        res.json(nlpResponse.data);\r\n+\r\n+        // âœ… Ensure correct structure\r\n+        const rewritten = nlpResponse.data.rewritten_text || sentence;\r\n+        res.json({ rewritten_text: rewritten });\r\n     } catch (error) {\r\n         console.error('Error proxying rewrite request:', error.message);\r\n         res.status(500).send('Error rewriting the sentence.');\r\n     }\r\n"
                },
                {
                    "date": 1762440484015,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -80,9 +80,125 @@\n     }\r\n \r\n     try {\r\n         const nlpResponse = await axios.post(\r\n-            'http://localhost:5001/rewrite',\r\n+            'http://localhost:5001/rewrite',// backend/routes/document.js\r\n+\r\n+const express = require('express');\r\n+const multer = require('multer');\r\n+const fs = require('fs');\r\n+const axios = require('axios');\r\n+const router = express.Router();\r\n+\r\n+// --- NEW IMPORTS ---\r\n+const path = require('path');\r\n+const pdf = require('pdf-parse');\r\n+const mammoth = require('mammoth');\r\n+// ---------------------\r\n+\r\n+const upload = multer({ dest: 'uploads/' });\r\n+\r\n+// --------------------------------------\r\n+// ðŸ“„ ROUTE: Upload and Analyze Document (UPDATED)\r\n+// --------------------------------------\r\n+router.post('/upload', upload.single('document'), async (req, res) => {\r\n+    if (!req.file) {\r\n+        return res.status(400).send('No file uploaded.');\r\n+    }\r\n+\r\n+    let fileContent = '';\r\n+    const filePath = req.file.path;\r\n+    const fileExt = path.extname(req.file.originalname).toLowerCase();\r\n+\r\n+    try {\r\n+        // --- NEW FILE PARSING LOGIC ---\r\n+        if (fileExt === '.txt') {\r\n+            fileContent = fs.readFileSync(filePath, 'utf8');\r\n+        } else if (fileExt === '.pdf') {\r\n+            const dataBuffer = fs.readFileSync(filePath);\r\n+            const data = await pdf(dataBuffer);\r\n+            fileContent = data.text;\r\n+        } else if (fileExt === '.docx') {\r\n+            const result = await mammoth.extractRawText({ path: filePath });\r\n+            fileContent = result.value;\r\n+        } else {\r\n+            fs.unlinkSync(filePath); // Delete temp file\r\n+            return res.status(400).send('Unsupported file type. Please upload .txt, .pdf, or .docx');\r\n+        }\r\n+        // --- END OF NEW LOGIC ---\r\n+\r\n+        // Delete temp uploaded file\r\n+        fs.unlinkSync(filePath);\r\n+\r\n+        // ðŸ”¹ Call NLP microservice\r\n+        const nlpResponse = await axios.post('http://localhost:5001/analyze', {\r\n+            text: fileContent\r\n+        });\r\n+\r\n+        const analysis = nlpResponse.data;\r\n+        \r\n+        // --- Logic to create 'Direct Match' and 'Paraphrased' types ---\r\n+        const flaggedSections = (analysis.flagged_sections || []).map(f => ({\r\n+            ...f,\r\n+            // Use python's type if available, otherwise, create one\r\n+            type: f.type || (f.similarity > 85 ? 'Direct Match' : 'Paraphrased')\r\n+        }));\r\n+\r\n+        // --- ðŸ” Build document visualizer data ---\r\n+        const visualizer = [];\r\n+        // Split text into sentences (a basic regex, can be improved)\r\n+        const sentences = fileContent.match(/[^.!?]+[.!?]*/g) || [fileContent];\r\n+\r\n+        sentences.forEach(sentence => {\r\n+            const s = sentence.trim();\r\n+            if (!s) return; // Skip empty strings\r\n+\r\n+            // Find the *best* match for this sentence\r\n+            let bestMatch = null;\r\n+            flaggedSections.forEach(f => {\r\n+                if (s.includes(f.text)) {\r\n+                    if (!bestMatch || f.similarity > bestMatch.similarity) {\r\n+                        bestMatch = f;\r\n+                    }\r\n+                }\r\n+            });\r\n+\r\n+            if (bestMatch) {\r\n+                visualizer.push({\r\n+                    text: s,\r\n+                    type: bestMatch.type, // 'Direct Match' or 'Paraphrased'\r\n+                    match: {\r\n+                        source: bestMatch.source || 'Unknown',\r\n+                        similarity: bestMatch.similarity || 0\r\n+                    }\r\n+                });\r\n+            } else {\r\n+                // This is unique. Do NOT add a 'type' field.\r\n+                visualizer.push({\r\n+                    text: s\r\n+                });\r\n+            }\r\n+        });\r\n+        \r\n+        // âœ… Send combined data\r\n+        res.status(200).json({\r\n+            overall_score: analysis.overall_score || 0,\r\n+            flagged_sections: flaggedSections, // This is the raw list from Python\r\n+            document_visualizer: visualizer, // This is the full text, tagged by sentence\r\n+            full_text: fileContent\r\n+        });\r\n+\r\n+    } catch (error) {\r\n+        // Clean up file on error\r\n+        if (fs.existsSync(filePath)) {\r\n+            fs.unlinkSync(filePath);\r\n+        }\r\n+        console.error('Error processing document:', error.message);\r\n+        res.status(500).send('Error analyzing the document.');\r\n+    }\r\n+});\r\n+\r\n+// ... (keep the rewrite route) ...\r\n             { sentence }\r\n         );\r\n \r\n         // âœ… Ensure correct structure\r\n"
                },
                {
                    "date": 1762440490167,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -196,8 +196,124 @@\n         res.status(500).send('Error analyzing the document.');\r\n     }\r\n });\r\n \r\n+// ... (keep the rewrite route) ...// backend/routes/document.js\r\n+\r\n+const express = require('express');\r\n+const multer = require('multer');\r\n+const fs = require('fs');\r\n+const axios = require('axios');\r\n+const router = express.Router();\r\n+\r\n+// --- NEW IMPORTS ---\r\n+const path = require('path');\r\n+const pdf = require('pdf-parse');\r\n+const mammoth = require('mammoth');\r\n+// ---------------------\r\n+\r\n+const upload = multer({ dest: 'uploads/' });\r\n+\r\n+// --------------------------------------\r\n+// ðŸ“„ ROUTE: Upload and Analyze Document (UPDATED)\r\n+// --------------------------------------\r\n+router.post('/upload', upload.single('document'), async (req, res) => {\r\n+    if (!req.file) {\r\n+        return res.status(400).send('No file uploaded.');\r\n+    }\r\n+\r\n+    let fileContent = '';\r\n+    const filePath = req.file.path;\r\n+    const fileExt = path.extname(req.file.originalname).toLowerCase();\r\n+\r\n+    try {\r\n+        // --- NEW FILE PARSING LOGIC ---\r\n+        if (fileExt === '.txt') {\r\n+            fileContent = fs.readFileSync(filePath, 'utf8');\r\n+        } else if (fileExt === '.pdf') {\r\n+            const dataBuffer = fs.readFileSync(filePath);\r\n+            const data = await pdf(dataBuffer);\r\n+            fileContent = data.text;\r\n+        } else if (fileExt === '.docx') {\r\n+            const result = await mammoth.extractRawText({ path: filePath });\r\n+            fileContent = result.value;\r\n+        } else {\r\n+            fs.unlinkSync(filePath); // Delete temp file\r\n+            return res.status(400).send('Unsupported file type. Please upload .txt, .pdf, or .docx');\r\n+        }\r\n+        // --- END OF NEW LOGIC ---\r\n+\r\n+        // Delete temp uploaded file\r\n+        fs.unlinkSync(filePath);\r\n+\r\n+        // ðŸ”¹ Call NLP microservice\r\n+        const nlpResponse = await axios.post('http://localhost:5001/analyze', {\r\n+            text: fileContent\r\n+        });\r\n+\r\n+        const analysis = nlpResponse.data;\r\n+        \r\n+        // --- Logic to create 'Direct Match' and 'Paraphrased' types ---\r\n+        const flaggedSections = (analysis.flagged_sections || []).map(f => ({\r\n+            ...f,\r\n+            // Use python's type if available, otherwise, create one\r\n+            type: f.type || (f.similarity > 85 ? 'Direct Match' : 'Paraphrased')\r\n+        }));\r\n+\r\n+        // --- ðŸ” Build document visualizer data ---\r\n+        const visualizer = [];\r\n+        // Split text into sentences (a basic regex, can be improved)\r\n+        const sentences = fileContent.match(/[^.!?]+[.!?]*/g) || [fileContent];\r\n+\r\n+        sentences.forEach(sentence => {\r\n+            const s = sentence.trim();\r\n+            if (!s) return; // Skip empty strings\r\n+\r\n+            // Find the *best* match for this sentence\r\n+            let bestMatch = null;\r\n+            flaggedSections.forEach(f => {\r\n+                if (s.includes(f.text)) {\r\n+                    if (!bestMatch || f.similarity > bestMatch.similarity) {\r\n+                        bestMatch = f;\r\n+                    }\r\n+                }\r\n+            });\r\n+\r\n+            if (bestMatch) {\r\n+                visualizer.push({\r\n+                    text: s,\r\n+                    type: bestMatch.type, // 'Direct Match' or 'Paraphrased'\r\n+                    match: {\r\n+                        source: bestMatch.source || 'Unknown',\r\n+                        similarity: bestMatch.similarity || 0\r\n+                    }\r\n+                });\r\n+            } else {\r\n+                // This is unique. Do NOT add a 'type' field.\r\n+                visualizer.push({\r\n+                    text: s\r\n+                });\r\n+            }\r\n+        });\r\n+        \r\n+        // âœ… Send combined data\r\n+        res.status(200).json({\r\n+            overall_score: analysis.overall_score || 0,\r\n+            flagged_sections: flaggedSections, // This is the raw list from Python\r\n+            document_visualizer: visualizer, // This is the full text, tagged by sentence\r\n+            full_text: fileContent\r\n+        });\r\n+\r\n+    } catch (error) {\r\n+        // Clean up file on error\r\n+        if (fs.existsSync(filePath)) {\r\n+            fs.unlinkSync(filePath);\r\n+        }\r\n+        console.error('Error processing document:', error.message);\r\n+        res.status(500).send('Error analyzing the document.');\r\n+    }\r\n+});\r\n+\r\n // ... (keep the rewrite route) ...\r\n             { sentence }\r\n         );\r\n \r\n"
                },
                {
                    "date": 1762440725611,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -5,91 +5,8 @@\n const fs = require('fs');\r\n const axios = require('axios');\r\n const router = express.Router();\r\n \r\n-const upload = multer({ dest: 'uploads/' });\r\n-\r\n-// --------------------------------------\r\n-// ðŸ“„ ROUTE: Upload and Analyze Document\r\n-// --------------------------------------\r\n-router.post('/upload', upload.single('document'), async (req, res) => {\r\n-    if (!req.file) {\r\n-        return res.status(400).send('No file uploaded.');\r\n-    }\r\n-\r\n-    try {\r\n-        const fileContent = fs.readFileSync(req.file.path, 'utf8');\r\n-\r\n-        // ðŸ”¹ Call NLP microservice\r\n-        const nlpResponse = await axios.post('http://localhost:5001/analyze', {\r\n-            text: fileContent\r\n-        });\r\n-\r\n-        // Delete temp uploaded file\r\n-        fs.unlinkSync(req.file.path);\r\n-\r\n-        const analysis = nlpResponse.data;\r\n-        const flaggedSections = (analysis.flagged_sections || []).map(f => ({\r\n-            ...f,\r\n-            type: f.type || (f.similarity > 85 ? 'direct' : 'paraphrased')\r\n-        }));\r\n-\r\n-        // --- ðŸ” Build document visualizer data ---\r\n-        const visualizer = [];\r\n-        const sentences = fileContent.match(/[^.!?]+[.!?]/g) || [fileContent];\r\n-\r\n-        sentences.forEach(sentence => {\r\n-            const match = flaggedSections.find(f => sentence.includes(f.text));\r\n-            if (match) {\r\n-                visualizer.push({\r\n-                    text: sentence.trim(),\r\n-                    type: match.type,\r\n-                    match: {\r\n-                        source: match.source || 'Unknown',\r\n-                        similarity: match.similarity || 0\r\n-                    }\r\n-                });\r\n-            } else {\r\n-                visualizer.push({\r\n-                    text: sentence.trim(),\r\n-                    type: 'unique'\r\n-                });\r\n-            }\r\n-        });\r\n-\r\n-        // âœ… Send combined data\r\n-        res.status(200).json({\r\n-            overall_score: analysis.overall_score || 0,\r\n-            flagged_sections: flaggedSections,\r\n-            document_visualizer: visualizer,\r\n-            full_text: fileContent\r\n-        });\r\n-\r\n-    } catch (error) {\r\n-        console.error('Error calling NLP service:', error.message);\r\n-        res.status(500).send('Error analyzing the document.');\r\n-    }\r\n-});\r\n-\r\n-// --------------------------------------\r\n-// âœï¸ ROUTE: Rewrite Sentence\r\n-// --------------------------------------\r\n-router.post('/rewrite', async (req, res) => {\r\n-    const { sentence } = req.body;\r\n-    if (!sentence) {\r\n-        return res.status(400).json({ msg: 'Sentence is required' });\r\n-    }\r\n-\r\n-    try {\r\n-        const nlpResponse = await axios.post(\r\n-            'http://localhost:5001/rewrite',// backend/routes/document.js\r\n-\r\n-const express = require('express');\r\n-const multer = require('multer');\r\n-const fs = require('fs');\r\n-const axios = require('axios');\r\n-const router = express.Router();\r\n-\r\n // --- NEW IMPORTS ---\r\n const path = require('path');\r\n const pdf = require('pdf-parse');\r\n const mammoth = require('mammoth');\r\n@@ -196,127 +113,27 @@\n         res.status(500).send('Error analyzing the document.');\r\n     }\r\n });\r\n \r\n-// ... (keep the rewrite route) ...// backend/routes/document.js\r\n-\r\n-const express = require('express');\r\n-const multer = require('multer');\r\n-const fs = require('fs');\r\n-const axios = require('axios');\r\n-const router = express.Router();\r\n-\r\n-// --- NEW IMPORTS ---\r\n-const path = require('path');\r\n-const pdf = require('pdf-parse');\r\n-const mammoth = require('mammoth');\r\n-// ---------------------\r\n-\r\n-const upload = multer({ dest: 'uploads/' });\r\n-\r\n // --------------------------------------\r\n-// ðŸ“„ ROUTE: Upload and Analyze Document (UPDATED)\r\n+// âœï¸ ROUTE: Rewrite Sentence (FIXED)\r\n // --------------------------------------\r\n-router.post('/upload', upload.single('document'), async (req, res) => {\r\n-    if (!req.file) {\r\n-        return res.status(400).send('No file uploaded.');\r\n+router.post('/rewrite', async (req, res) => {\r\n+    const { sentence } = req.body;\r\n+    if (!sentence) {\r\n+        return res.status(400).json({ msg: 'Sentence is required' });\r\n     }\r\n \r\n-    let fileContent = '';\r\n-    const filePath = req.file.path;\r\n-    const fileExt = path.extname(req.file.originalname).toLowerCase();\r\n-\r\n     try {\r\n-        // --- NEW FILE PARSING LOGIC ---\r\n-        if (fileExt === '.txt') {\r\n-            fileContent = fs.readFileSync(filePath, 'utf8');\r\n-        } else if (fileExt === '.pdf') {\r\n-            const dataBuffer = fs.readFileSync(filePath);\r\n-            const data = await pdf(dataBuffer);\r\n-            fileContent = data.text;\r\n-        } else if (fileExt === '.docx') {\r\n-            const result = await mammoth.extractRawText({ path: filePath });\r\n-            fileContent = result.value;\r\n-        } else {\r\n-            fs.unlinkSync(filePath); // Delete temp file\r\n-            return res.status(400).send('Unsupported file type. Please upload .txt, .pdf, or .docx');\r\n-        }\r\n-        // --- END OF NEW LOGIC ---\r\n-\r\n-        // Delete temp uploaded file\r\n-        fs.unlinkSync(filePath);\r\n-\r\n-        // ðŸ”¹ Call NLP microservice\r\n-        const nlpResponse = await axios.post('http://localhost:5001/analyze', {\r\n-            text: fileContent\r\n-        });\r\n-\r\n-        const analysis = nlpResponse.data;\r\n-        \r\n-        // --- Logic to create 'Direct Match' and 'Paraphrased' types ---\r\n-        const flaggedSections = (analysis.flagged_sections || []).map(f => ({\r\n-            ...f,\r\n-            // Use python's type if available, otherwise, create one\r\n-            type: f.type || (f.similarity > 85 ? 'Direct Match' : 'Paraphrased')\r\n-        }));\r\n-\r\n-        // --- ðŸ” Build document visualizer data ---\r\n-        const visualizer = [];\r\n-        // Split text into sentences (a basic regex, can be improved)\r\n-        const sentences = fileContent.match(/[^.!?]+[.!?]*/g) || [fileContent];\r\n-\r\n-        sentences.forEach(sentence => {\r\n-            const s = sentence.trim();\r\n-            if (!s) return; // Skip empty strings\r\n-\r\n-            // Find the *best* match for this sentence\r\n-            let bestMatch = null;\r\n-            flaggedSections.forEach(f => {\r\n-                if (s.includes(f.text)) {\r\n-                    if (!bestMatch || f.similarity > bestMatch.similarity) {\r\n-                        bestMatch = f;\r\n-                    }\r\n-                }\r\n-            });\r\n-\r\n-            if (bestMatch) {\r\n-                visualizer.push({\r\n-                    text: s,\r\n-                    type: bestMatch.type, // 'Direct Match' or 'Paraphrased'\r\n-                    match: {\r\n-                        source: bestMatch.source || 'Unknown',\r\n-                        similarity: bestMatch.similarity || 0\r\n-                    }\r\n-                });\r\n-            } else {\r\n-                // This is unique. Do NOT add a 'type' field.\r\n-                visualizer.push({\r\n-                    text: s\r\n-                });\r\n+        // ðŸ”½ --- THIS IS THE FIX --- ðŸ”½\r\n+        const nlpResponse = await axios.post(\r\n+            'http://localhost:5001/api/rewrite', // Was 'http://localhost:5001/rewrite'\r\n+            { \r\n+              sentence,\r\n+              // api_key: \"YOUR_API_KEY\" // Add this if your python service needs one\r\n             }\r\n-        });\r\n-        \r\n-        // âœ… Send combined data\r\n-        res.status(200).json({\r\n-            overall_score: analysis.overall_score || 0,\r\n-            flagged_sections: flaggedSections, // This is the raw list from Python\r\n-            document_visualizer: visualizer, // This is the full text, tagged by sentence\r\n-            full_text: fileContent\r\n-        });\r\n-\r\n-    } catch (error) {\r\n-        // Clean up file on error\r\n-        if (fs.existsSync(filePath)) {\r\n-            fs.unlinkSync(filePath);\r\n-        }\r\n-        console.error('Error processing document:', error.message);\r\n-        res.status(500).send('Error analyzing the document.');\r\n-    }\r\n-});\r\n-\r\n-// ... (keep the rewrite route) ...\r\n-            { sentence }\r\n         );\r\n+        // ðŸ”¼ --- END OF FIX --- ðŸ”¼\r\n \r\n         // âœ… Ensure correct structure\r\n         const rewritten = nlpResponse.data.rewritten_text || sentence;\r\n         res.json({ rewritten_text: rewritten });\r\n@@ -325,5 +142,5 @@\n         res.status(500).send('Error rewriting the sentence.');\r\n     }\r\n });\r\n \r\n-module.exports = router;\r\n+module.exports = router;\n\\ No newline at end of file\n"
                },
                {
                    "date": 1762524753259,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,146 +1,95 @@\n-// backend/routes/document.js\r\n-\r\n const express = require('express');\r\n const multer = require('multer');\r\n const fs = require('fs');\r\n+const path = require('path');\r\n const axios = require('axios');\r\n const router = express.Router();\r\n \r\n-// --- NEW IMPORTS ---\r\n-const path = require('path');\r\n+// New libraries\r\n const pdf = require('pdf-parse');\r\n const mammoth = require('mammoth');\r\n-// ---------------------\r\n \r\n const upload = multer({ dest: 'uploads/' });\r\n \r\n-// --------------------------------------\r\n-// ðŸ“„ ROUTE: Upload and Analyze Document (UPDATED)\r\n-// --------------------------------------\r\n+// Function to get plain text from different file types\r\n+const getTextFromFile = async (file) => {\r\n+    const ext = path.extname(file.originalname).toLowerCase();\r\n+    const filePath = file.path;\r\n+\r\n+    if (ext === '.txt') {\r\n+        return fs.readFileSync(filePath, 'utf8');\r\n+    } \r\n+\r\n+    else if (ext === '.pdf') {\r\n+        const dataBuffer = fs.readFileSync(filePath);\r\n+        const data = await pdf(dataBuffer);\r\n+        return data.text;\r\n+    } \r\n+\r\n+    else if (ext === '.docx') {\r\n+        const result = await mammoth.extractRawText({ path: filePath });\r\n+        return result.value;\r\n+    } \r\n+\r\n+    else if (ext === '.doc') {\r\n+        // .doc is a complex, proprietary format.\r\n+        // For this project, we'll ask users to re-save as .docx or .pdf\r\n+        throw new Error('\".doc\" files are not supported. Please save as .docx or .pdf');\r\n+    }\r\n+\r\n+    else {\r\n+        throw new Error('Unsupported file type.');\r\n+    }\r\n+};\r\n+\r\n+// @route   POST /api/documents/upload\r\n router.post('/upload', upload.single('document'), async (req, res) => {\r\n     if (!req.file) {\r\n         return res.status(400).send('No file uploaded.');\r\n     }\r\n \r\n-    let fileContent = '';\r\n-    const filePath = req.file.path;\r\n-    const fileExt = path.extname(req.file.originalname).toLowerCase();\r\n-\r\n     try {\r\n-        // --- NEW FILE PARSING LOGIC ---\r\n-        if (fileExt === '.txt') {\r\n-            fileContent = fs.readFileSync(filePath, 'utf8');\r\n-        } else if (fileExt === '.pdf') {\r\n-            const dataBuffer = fs.readFileSync(filePath);\r\n-            const data = await pdf(dataBuffer);\r\n-            fileContent = data.text;\r\n-        } else if (fileExt === '.docx') {\r\n-            const result = await mammoth.extractRawText({ path: filePath });\r\n-            fileContent = result.value;\r\n-        } else {\r\n-            fs.unlinkSync(filePath); // Delete temp file\r\n-            return res.status(400).send('Unsupported file type. Please upload .txt, .pdf, or .docx');\r\n-        }\r\n-        // --- END OF NEW LOGIC ---\r\n+        // 1. Get text content using our new function\r\n+        const fileContent = await getTextFromFile(req.file);\r\n \r\n-        // Delete temp uploaded file\r\n-        fs.unlinkSync(filePath);\r\n-\r\n-        // ðŸ”¹ Call NLP microservice\r\n-        const nlpResponse = await axios.post('http://localhost:5001/analyze', {\r\n+        // 2. Call the NLP service (this URL is now correct)\r\n+        const nlpResponse = await axios.post('http://localhost:5001/api/check', {\r\n             text: fileContent\r\n         });\r\n \r\n-        const analysis = nlpResponse.data;\r\n-        \r\n-        // --- Logic to create 'Direct Match' and 'Paraphrased' types ---\r\n-        const flaggedSections = (analysis.flagged_sections || []).map(f => ({\r\n-            ...f,\r\n-            // Use python's type if available, otherwise, create one\r\n-            type: f.type || (f.similarity > 85 ? 'Direct Match' : 'Paraphrased')\r\n-        }));\r\n+        // 3. Send the detailed report back to the frontend\r\n+        res.status(200).json(nlpResponse.data);\r\n \r\n-        // --- ðŸ” Build document visualizer data ---\r\n-        const visualizer = [];\r\n-        // Split text into sentences (a basic regex, can be improved)\r\n-        const sentences = fileContent.match(/[^.!?]+[.!?]*/g) || [fileContent];\r\n-\r\n-        sentences.forEach(sentence => {\r\n-            const s = sentence.trim();\r\n-            if (!s) return; // Skip empty strings\r\n-\r\n-            // Find the *best* match for this sentence\r\n-            let bestMatch = null;\r\n-            flaggedSections.forEach(f => {\r\n-                if (s.includes(f.text)) {\r\n-                    if (!bestMatch || f.similarity > bestMatch.similarity) {\r\n-                        bestMatch = f;\r\n-                    }\r\n-                }\r\n-            });\r\n-\r\n-            if (bestMatch) {\r\n-                visualizer.push({\r\n-                    text: s,\r\n-                    type: bestMatch.type, // 'Direct Match' or 'Paraphrased'\r\n-                    match: {\r\n-                        source: bestMatch.source || 'Unknown',\r\n-                        similarity: bestMatch.similarity || 0\r\n-                    }\r\n-                });\r\n-            } else {\r\n-                // This is unique. Do NOT add a 'type' field.\r\n-                visualizer.push({\r\n-                    text: s\r\n-                });\r\n-            }\r\n-        });\r\n-        \r\n-        // âœ… Send combined data\r\n-        res.status(200).json({\r\n-            overall_score: analysis.overall_score || 0,\r\n-            flagged_sections: flaggedSections, // This is the raw list from Python\r\n-            document_visualizer: visualizer, // This is the full text, tagged by sentence\r\n-            full_text: fileContent\r\n-        });\r\n-\r\n     } catch (error) {\r\n-        // Clean up file on error\r\n-        if (fs.existsSync(filePath)) {\r\n-            fs.unlinkSync(filePath);\r\n-        }\r\n-        console.error('Error processing document:', error.message);\r\n-        res.status(500).send('Error analyzing the document.');\r\n+        console.error('Error processing file:', error.message);\r\n+        res.status(500).send(error.message || 'Error analyzing the document.');\r\n+    } finally {\r\n+        // 4. Clean up the uploaded file\r\n+        fs.unlinkSync(req.file.path);\r\n     }\r\n });\r\n \r\n-// --------------------------------------\r\n-// âœï¸ ROUTE: Rewrite Sentence (FIXED)\r\n-// --------------------------------------\r\n+// @route   POST /api/documents/rewrite\r\n+// (This route remains unchanged and correct)\r\n router.post('/rewrite', async (req, res) => {\r\n     const { sentence } = req.body;\r\n     if (!sentence) {\r\n         return res.status(400).json({ msg: 'Sentence is required' });\r\n     }\r\n \r\n     try {\r\n-        // ðŸ”½ --- THIS IS THE FIX --- ðŸ”½\r\n         const nlpResponse = await axios.post(\r\n-            'http://localhost:5001/api/rewrite', // Was 'http://localhost:5001/rewrite'\r\n-            { \r\n-              sentence,\r\n-              // api_key: \"YOUR_API_KEY\" // Add this if your python service needs one\r\n+            `http://localhost:5001/api/rewrite`,\r\n+            {\r\n+                sentence: sentence,\r\n+                api_key: process.env.GEMINI_API_KEY \r\n             }\r\n         );\r\n-        // ðŸ”¼ --- END OF FIX --- ðŸ”¼\r\n-\r\n-        // âœ… Ensure correct structure\r\n-        const rewritten = nlpResponse.data.rewritten_text || sentence;\r\n-        res.json({ rewritten_text: rewritten });\r\n+        res.json(nlpResponse.data);\r\n     } catch (error) {\r\n-        console.error('Error proxying rewrite request:', error.message);\r\n-        res.status(500).send('Error rewriting the sentence.');\r\n+        console.error('Error calling rewrite service:', error.message);\r\n+        res.status(500).send('Error generating rewrite.');\r\n     }\r\n });\r\n \r\n module.exports = router;\n\\ No newline at end of file\n"
                }
            ],
            "date": 1762431758746,
            "name": "Commit-0",
            "content": "const express = require('express');\r\nconst multer = require('multer');\r\nconst fs = require('fs');\r\nconst axios = require('axios');\r\nconst auth = require('../middleware/authMiddleware'); // âœ… Secure routes\r\n\r\nconst router = express.Router();\r\nconst upload = multer({ dest: 'uploads/' });\r\n\r\n// -----------------------------------------\r\n// @route   POST /api/documents/upload\r\n// @desc    Uploads a document and analyzes via NLP microservice\r\n// @access  Private\r\n// -----------------------------------------\r\nrouter.post('/upload', auth, upload.single('document'), async (req, res) => {\r\n    if (!req.file) {\r\n        return res.status(400).send('No file uploaded.');\r\n    }\r\n\r\n    const filePath = req.file.path;\r\n\r\n    try {\r\n        const fileContent = fs.readFileSync(filePath, 'utf8');\r\n\r\n        // âœ… Updated endpoint to match new Python service route\r\n        const nlpResponse = await axios.post('http://localhost:5001/analyze', {\r\n            text: fileContent\r\n        });\r\n\r\n        res.status(200).json(nlpResponse.data);\r\n    } catch (error) {\r\n        console.error('Error calling NLP service:', error.message);\r\n        res.status(500).send('Error analyzing the document.');\r\n    } finally {\r\n        // âœ… Always delete uploaded temp file safely\r\n        if (fs.existsSync(filePath)) fs.unlinkSync(filePath);\r\n    }\r\n});\r\n\r\n// -----------------------------------------\r\n// @route   POST /api/documents/rewrite\r\n// @desc    Proxies rewrite requests securely to the Python microservice\r\n// @access  Private\r\n// -----------------------------------------\r\nrouter.post('/rewrite', auth, async (req, res) => {\r\n    const { sentence } = req.body;\r\n    if (!sentence) {\r\n        return res.status(400).json({ msg: 'Sentence is required' });\r\n    }\r\n\r\n    try {\r\n        // âœ… Matches new /rewrite route in app.py\r\n        const nlpResponse = await axios.post('http://localhost:5001/rewrite', {\r\n            sentence,\r\n            api_key: process.env.GEMINI_API_KEY\r\n        });\r\n\r\n        res.json(nlpResponse.data);\r\n    } catch (error) {\r\n        console.error('Error proxying rewrite request:', error.message);\r\n        res.status(500).send('Error rewriting the sentence.');\r\n    }\r\n});\r\n\r\nmodule.exports = router;\r\n"
        }
    ]
}